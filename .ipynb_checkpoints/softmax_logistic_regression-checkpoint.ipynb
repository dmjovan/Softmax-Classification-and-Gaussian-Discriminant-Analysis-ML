{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13226b2e-e686-4707-bcc7-e6747ca3108a",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Učitavanje biblioteka za rad "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fc6717e-fa4b-41f8-a255-d8b8b0b644e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9d0f7648-c424-456d-9d3b-6403b06c9ccd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Na osnovu broja indeksa, potrebno je implementirati sledeca 2 algoritma: \n",
      " - Softmax logisticka regresija i \n",
      " - Gauss-ovska diskriminativna analiza\n"
     ]
    }
   ],
   "source": [
    "# broj indeksa za studenta Jovan Dmitrović\n",
    "ind = '2021/3096'\n",
    "\n",
    "# odredjivanje algoritama koje je potrebno implementirati\n",
    "B3 = int(ind[-2])\n",
    "B4 = int(ind[-1])\n",
    "\n",
    "even_num = lambda num: True if num%2 == 0 else False\n",
    "\n",
    "algos_dict = {(False, False): ['Softmax logisticka regresija', 'Gauss-ovski naivni Bayes'],\n",
    "             (False, True) : ['Softmax logisticka regresija', 'Gauss-ovska diskriminativna analiza'],\n",
    "             (True, False) : ['Logisticka regresija', 'Gauss-ovski naivni Bayes'],\n",
    "             (True, True)  : ['Logisticka regresija', 'Gauss-ovska diskriminativna analiza']}\n",
    "\n",
    "algos_selected = algos_dict[(even_num(B3), even_num(B4))]\n",
    "\n",
    "print(f'Na osnovu broja indeksa, potrebno je implementirati sledeca 2 algoritma: \\n - {algos_selected[0]} i \\n - {algos_selected[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e43abb0-5571-4376-ac93-cdd562f07b76",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Učitavanje podataka "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2c2b51e3-8feb-404f-b4f5-e84de96af940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes_info(y: np.ndarray, show_text: bool=True) -> int:\n",
    "    \n",
    "    \"\"\"\n",
    "        Funkcija za izvlacenje klasa i prebrojavanja primera\n",
    "        sa istom klasom\n",
    "        \n",
    "        params: \n",
    "            - y: vektor klasa\n",
    "                               \n",
    "        :return:\n",
    "            - k: broj klasa\n",
    "    \"\"\"\n",
    "    # dohvatanje svih vrednosti klasa\n",
    "    classes = []\n",
    "    for _class in y:\n",
    "        if _class not in classes:\n",
    "            classes.append(int(_class))\n",
    "            \n",
    "    # prebrojavanje predstavnika klasa\n",
    "    classes_dict = dict.fromkeys(classes)\n",
    "    for _class in classes:\n",
    "        class_count = np.count_nonzero(y == _class)\n",
    "        classes_dict[_class] = class_count\n",
    "        \n",
    "    # broj klasa\n",
    "    k = len(classes_dict.keys())\n",
    "        \n",
    "    # ispis podataka o klasama u dataset-u\n",
    "    if show_text:\n",
    "        print('-------------------------------------------------------')\n",
    "        print(f'Ukupan broj klasa kojima pripadaju ucitani primeri je: {k}\\n')\n",
    "        print('Ucitane klase i brojevi njhovih predstavnika/primera su: ')\n",
    "        for _class in classes_dict.keys():\n",
    "            print(f'\\tKlasa {_class}: {classes_dict[_class]} primera')\n",
    "        print('-------------------------------------------------------')\n",
    "    \n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cc601037-1b28-4542-91b1-7952c600f0a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------Ucitani su podaci-------------------\n",
      "Ukupan broj ucitanih primera je: 177\n",
      "Ukupan broj ucitanih prediktora (dim(X)) je: 5\n",
      "-------------------------------------------------------\n",
      "Ukupan broj klasa kojima pripadaju ucitani primeri je: 3\n",
      "\n",
      "Ucitane klase i brojevi njhovih predstavnika/primera su: \n",
      "\tKlasa 0: 58 primera\n",
      "\tKlasa 1: 71 primera\n",
      "\tKlasa 2: 48 primera\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('multiclass_data.csv').to_numpy()\n",
    "X, y = data[:,0:5], data[:,5]\n",
    "\n",
    "print('-------------------Ucitani su podaci-------------------')\n",
    "print(f'Ukupan broj ucitanih primera je: {X.shape[0]}')\n",
    "print(f'Ukupan broj ucitanih prediktora (dim(X)) je: {X.shape[1]}')\n",
    "\n",
    "k = get_classes_info(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09ddccea-7706-421e-804a-95ac780d2ebb",
   "metadata": {},
   "source": [
    "Klase nisu \"savršeno balansirane\" (pojednaka brojčane), medjutim ne može se reći ni da su nebalansirane, s obzirom na to da broj primera svake pojedinačne klase nije drastično mali, npr. klasa 2 ima 3 odbirka. \\\n",
    "Ovaj problem nebalansiranih klasa moguće \"rešiti\", tj. unekoliko poboljšati vršenjem takozvanog *oversampling*-a, ne bi li se broj primera najnemnogobrojnije klase iole mogao izjednačiti sa ostalim klasama, ili otežinjavanjem primera najnemnogobrojnije klase prilikom računanje funkcije gubitka. \\\n",
    "*Oversampling* podrazumeva da se pomoću estimirane raspodele podataka najnemnogobrojnije klase, generišu neki novi podaci koji navodno pripadaju toj klasi (često se za ovaj postupak upotrebljava k-Nearest-Neighbours algoritam). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfbfb7f4-f624-48e9-b4a3-d63b309eeae3",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Teorijski osvrt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7267766c-8508-4a8e-9c51-257b7d5c8f6b",
   "metadata": {},
   "source": [
    "Logistička regresija je algoritam za binarnu klasifikaciju. Ne može se primeniti direktno u slučajevima kada postoji više od dve ciljne klase. Jedna mogućnost je tzv \"jedan-protiv-ostalih\" strategija: za svaku klasu projektuje se po jedan binarni klasifikator, koji odlučuje da li primer pripada toj klasi ili ne. Druga mogućnost je \"jedan-protiv-jednog\", gde projektujemo po jedan klasifikator za svaki par klasa.\n",
    "\n",
    "\n",
    "**Multinomijalna logistička regresija**, poznatija pod nazivom **Softmax** klasifikator, prirodno podržava probleme sa više od 2 ciljne klase. U pitanju je generalizovani linearni model koji izlaznoj promenljivoj $y$ pridružuje multinomijalnu raspodelu:\n",
    "$$\n",
    "\\Pr(Y=i) = \\phi_i, \\quad i=1, \\ldots, k\n",
    "\\\\\n",
    "\\sum_{i=1}^k \\phi_i = 1\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e67757-3752-4a2d-848f-94e47b5dedef",
   "metadata": {},
   "source": [
    "# Implementacija potrebnih funkcija"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3603b4f8-86fa-401a-8c30-c7bf1c4cbb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path: str='multiclass_data.csv', separator_index: int=5) -> tuple:\n",
    "    \n",
    "    \"\"\"\n",
    "        Funkcija za ucitavanje podataka na osnovu kojih se\n",
    "        kreira model.\n",
    "        \n",
    "        :params: \n",
    "            - path: putanja do .csv fajla sa podacima\n",
    "            - separator_index: broj kolone do koje se nalaze\n",
    "                               ulazni podaci, odnosno od koje\n",
    "                               pocinju izlazni podaci\n",
    "                               \n",
    "        :return:\n",
    "            - X: matrica primera svih prediktora\n",
    "            - y: vektor izlaza\n",
    "    \"\"\"\n",
    "    \n",
    "    data = pd.read_csv(path).to_numpy()\n",
    "    \n",
    "    # razdvajanje ulaznih i izlaznih promenljivih\n",
    "    X, y = data[:,0:separator_index], data[:,separator_index]\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37019365-a01e-43c7-a531-c37058b41ede",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data(X: np.ndarray, y: np.ndarray) -> tuple:\n",
    "    \n",
    "    \"\"\"\n",
    "        Funkcija za mesanje primera. Klase su u uzlanom .csv fajlu skoncentrisane\n",
    "        u grupe prilikom ucitavanja. Razdvajanje podataka na trening i na test\n",
    "        podatke dovelo bi do nebalansiranja klasa, sto se izbegava mesanjem klasa.\n",
    "        \n",
    "        :params:\n",
    "            - X: matrica primera svih prediktora\n",
    "            - y: vektor klasa\n",
    "                           \n",
    "        :return:\n",
    "            - X: izmesana matrica primera svih prediktora\n",
    "            - y: izmesan vektor klasa\n",
    "    \"\"\"\n",
    "\n",
    "    random.seed(1)\n",
    "    \n",
    "    # dohvatanje broja primera u ulaznim podacima\n",
    "    m = X.shape[0]\n",
    "    \n",
    "    # kreiranje niza indeksa\n",
    "    indeces = np.arange(0,m)\n",
    "\n",
    "    # mesanje indeksa\n",
    "    shuffled_indeces = random.sample(list(indeces), m)\n",
    "\n",
    "    return X[shuffled_indeces], y[shuffled_indeces]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90962e4d-6618-412e-bc8d-2067201e2704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_data_split(X: np.ndarray, y: np.ndarray, split_ratio: float=0.8) -> tuple:\n",
    "    \n",
    "    \"\"\"\n",
    "        Funkcija za mesanje klasa i splitovanje svih dostupnih podataka na \n",
    "        trening/obucavajuce i test podatke prema zadatom postotku (split_ratio).\n",
    "        \n",
    "        :params:\n",
    "            - X: matrica primera svih prediktora\n",
    "            - y: vektor izlaza\n",
    "            - split_ratio: vrednost iz intervala [0,1] koja oznacava procenat\n",
    "                           trening podataka\n",
    "                           \n",
    "        :return:\n",
    "            - X_train: matrica primera svih prediktora za trening skup\n",
    "            - y_train: vektor izlaza za trening skup\n",
    "            - X_test: matrica primera svih prediktora za test skup\n",
    "            - y_test: vektro izlaza za test skup\n",
    "    \"\"\"\n",
    "    \n",
    "    random.seed(1)\n",
    "    \n",
    "    m = X.shape[0]\n",
    "    \n",
    "    train_set_size = int(m*split_ratio)\n",
    "    \n",
    "    ind = np.arange(0,m).tolist()\n",
    "    \n",
    "    # odredjivanje indeksa za trening skup\n",
    "    train_set_ind = random.sample(ind, k=train_set_size)\n",
    "    \n",
    "    # odredjivanje indeksa za test skup\n",
    "    test_set_ind = list(set(ind) - set(train_set_ind))\n",
    "    \n",
    "    # mesanje podataka\n",
    "    X, y = shuffle_data(X, y)\n",
    "    \n",
    "    # podela podataka na trening i test podatke\n",
    "    X_train, y_train = X[train_set_ind], y[train_set_ind]\n",
    "    X_test, y_test = X[test_set_ind], y[test_set_ind]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5385056-e396-48b6-8132-013042abf6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_statistics(X: np.ndarray) -> tuple:\n",
    "    \n",
    "    \"\"\"\n",
    "        Funkcija za dohvatanje statistika - srednja vrednost i standardna devijacija. \n",
    "        Za svaka od kolona matrice X vrsi se izracunavanje statistika, s obzirom na to da\n",
    "        one predstavljaju posebne prediktore.\n",
    "        \n",
    "        :params:\n",
    "            - X: matrica primera svih prediktora\n",
    "            \n",
    "        :return:\n",
    "            - mu: vektor srednjih vrednosti za svaki prediktor\n",
    "            - std: vektor standardnih devijacija za svaki prediktor\n",
    "    \"\"\"\n",
    "    \n",
    "    # broj prediktora\n",
    "    n = X.shape[1]\n",
    "    \n",
    "    # vektor srednjih vrednosti za svaki prediktor ponaosob\n",
    "    mu = np.zeros(n)\n",
    "    \n",
    "    # vektor standardnih devijacija za svaki prediktor ponaosob\n",
    "    std = np.zeros(n)\n",
    "    \n",
    "    for i in range(n):\n",
    "        mu[i] = np.mean(X[:,i])\n",
    "        std[i] = np.std(X[:,i])\n",
    "    \n",
    "    return mu, std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20b5900b-9ead-472b-99d3-ec7810ca52e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(X: np.ndarray, mu: np.ndarray=None, std: np.ndarray=None) -> np.ndarray:\n",
    "    \n",
    "    \"\"\"\n",
    "        Funkcija za standardizaciju prediktora - postavljanje prediktora na istu skalu.\n",
    "        Svaka kolona matrice X se standardizuje sa sebi svojstvenim statistikama - mu i std,\n",
    "        s obzirom na to da su to posebni prediktori i da u opstem slucaju ne moraju biti na istoj skali.\n",
    "        \n",
    "        :params:\n",
    "            - X: matrica primera svih prediktora\n",
    "            - mu: vektor srednjih vrednosti za svaki prediktor ili None\n",
    "            - std: vektor standardnih devijacija za svaki prediktor ili None\n",
    "            \n",
    "        :return:\n",
    "            - X: standardizovana matrica primera svih prediktora\n",
    "    \"\"\"\n",
    "    \n",
    "    # racunanje srednjih vrednosti i st. devijacije svih prediktora\n",
    "    if mu is None and std is None:\n",
    "        mu, std = np.mean(X, axis=0), np.std(X, axis=0)\n",
    "\n",
    "    # standardizacija na normalnu raspodelu\n",
    "    X = (X - mu) / std # ~ N(0,1)\n",
    "    \n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "08ffab67-cd80-40d1-8a72-f2f801e3d697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ucitavanje podataka\n",
    "X, y = read_data()\n",
    "\n",
    "# broj primera\n",
    "m = X.shape[0]\n",
    "\n",
    "# broj prediktora\n",
    "n = X.shape[1]\n",
    "\n",
    "# broj klasa\n",
    "k = get_classes_info(y, show_text=False)\n",
    "\n",
    "# podela podataka na trening i test skup\n",
    "X_train, y_train, X_test, y_test = train_test_data_split(X, y, split_ratio=0.8)\n",
    "\n",
    "# podela trening podataka na trening i validacioni skup\n",
    "X_train, y_train, X_val, y_val = train_test_data_split(X_train, y_train, split_ratio=0.8)\n",
    "\n",
    "# dohvatanje sr. vrednosti i st. devijacije trening skupa\n",
    "mu, std = get_statistics(X_train)\n",
    "\n",
    "# standardizacija trening skupa \n",
    "X_train = standardize(X_train)\n",
    "\n",
    "# standardizacija validacionog skupa sa statistikama iz trening skupa\n",
    "X_val = standardize(X_val, mu, std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d5667fde-770b-4771-a48e-f1e37e8f17bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [TODO] - racunanje loss-a\n",
    "# [TODO] - racunanje gradienta\n",
    "# [TODO] - jednokoracni gradijent sa razlicitim learning_rate-om\n",
    "# [TODO] - treniranje\n",
    "# [TODO] - prikaz rezultata treniranja\n",
    "# [TODO] - predikcija (u vidu verovatnoca za i-ti primer po svim klasama)\n",
    "# [TODO] - predikcija (u vidu izvlacenja one klase sa najvecom verovatnocom)\n",
    "# [TODO] - racunanje predikcija i metrika tacnosti (confusion_matrix) za trening, validacioni i test skup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7761808f-69a3-4ae1-a3d7-1cc520c2a73a",
   "metadata": {},
   "source": [
    "Ovaj model, generalno ima 2 hiper parametra:\n",
    "- red polinoma - p\n",
    "- jačina regularizacije - $\\lambda$.\n",
    "\n",
    "Red polinoma je u zadatku fiksiran, tako da je potrebno samo pronaći optimlano $\\lambda$.\\\n",
    "Optimalan parametar $\\lambda$ odredjuje se unakrsnom validacijom, pri čemu vršimo pretragu po svim lambdama iz nekog opsega.\n",
    "\n",
    "Unaksne validacija (*eng. cross validation*) jeste jedna od najboljih metoda za procenu performansi modela.\\\n",
    "To je postupak u kojem celi skup podataka (uglavnom skup podataka koji su rezervisani za obučavanje) podelimo na *k* delova, tzv. foldovi, jedan fold podataka proglasimo \n",
    "da je validacioni skup, a preostalih *k-1* proglasimo da pripadaju obučavajućem skupu. Zatim \"istreniramo\" naš model na novonastalom obučavajućem skupu (i uzmemo vrednosti metrika) i \n",
    "izracunamo vrednost adekvatne metrike tako dobijenog modela za predikcije iz validacionog skupa. To sve ponavljamo *k* puta, uzimajući uvek različiti set podataka za validacioni skup.\\\n",
    "Na kraju samo usrednjimo dobijene metrike i dobijamo procenu metrike (npr. srednje kvadratna greška izlaza), odnosno procenu tačnosti našeg modela na validacionom skupu. \n",
    "\n",
    "Ovakav postupan možemo da ponavljamo za svako $\\lambda$ iz nekog opsega vrednosti. Ono $\\lambda$ koje na validacionom skupu daje minimalnu (minimalnu ukoliko je metrika nenegativna kao npr. (R)MSE) grešku, proglašavamo našim optimalnim parametrom $\\lambda$. \n",
    "\n",
    "Taj postupak vrši se priloženim kodom ispod. \n",
    "\n",
    "Potrebno je još spomenuti, da je, radi procene stvarne greške modela u produkciji, celokupan skup podataka potrebno je podeliti na dva podskupa:\n",
    "- obučavajući - uglavnom čini od 70 do 90% ukupnih podataka\n",
    "- testirajući - uglavnom čini od 10 do 30% ukupnih podataka\n",
    "\n",
    "Na obučavajućem ili trening skupu sve vrši treniranje modela, unakrsna validacija i pronalaženje optimalnog $\\lambda$, a na testirajućem skupu se vrši merenje performansi modela kroz adekvatnu metriku."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "828e569f-5153-4bf3-ae7d-40c1006ff180",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'make_polynomial_features' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-2f6026b313d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# kreiranje polinomijalnih prediktora za trening skup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mX_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmake_polynomial_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# formiranje niza svih mogucih vrednosti za hiper-parametar lambda\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'make_polynomial_features' is not defined"
     ]
    }
   ],
   "source": [
    "# ucitavanje podataka\n",
    "X, y = read_data()\n",
    "\n",
    "# podela podataka na trening i test skup\n",
    "X_train, y_train, X_test, y_test = train_test_data_split(X, y, split_ratio=0.8)\n",
    "\n",
    "# kreiranje polinomijalnih prediktora za trening skup\n",
    "X_train = make_polynomial_features(X_train)\n",
    "\n",
    "# formiranje niza svih mogucih vrednosti za hiper-parametar lambda\n",
    "lambdas = np.linspace(0.1, 100, 200)\n",
    "\n",
    "# pretraga unakrsnom validacijom za optimalno lambda\n",
    "lambda_opt = optimal_lambda_search(X_train, y_train, lambdas, k=5, rmse=False, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2e8d25-4129-459f-ba99-1743aad38c4e",
   "metadata": {},
   "source": [
    "Dakle, pronadjena optimalna vrednost hiper-parametra $\\lambda$ iznosi otprilike 24. Ova vrednost na prestavlja ni preveliku, ni premalu vrednost za ovaj hiper-parametar, u smislu da daje adekvatna regularizaciju modela. Premalo $\\lambda$, npr. 1e-5 značilo bi da regularizacije modela uopšte nema, dok bi veliko $\\lambda$, npr. 1000 značilo da se model previše regularizuje i da se preveliki znacaj pridaje parametrima modela, a ne i performansama modela.\\\n",
    "Zbog toga optimalna vrednost $\\lambda$ hiper-parametra dovoljno dobro vrši regularizaciju, penalizujući parametre modela, ali i predikcije takvog modela su dovoljno dobre, što je suština ove pretrage. \n",
    "\n",
    "Potrebno je samo argumentovati da je na prikazanom grafiku sa razlogom prikazana zavisnost MSE-a od hiper-parametra $\\lambda$, a ne funkcija gubitka modela, jer se na taj način odredjivanjem $\\lambda$ kao argumenta koji daje minimalno MSE na validacionom skupu, nešto veći značaj pridaje tačnoj predikciji nego parametrima modela."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239b1438-4fdb-49e0-9649-2589caf247bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# racunanje finalnih parametara modela\n",
    "theta, theta0 = train_with_optimal_lambda(X_train, y_train, lambda_opt)\n",
    "\n",
    "# cuvanje finalnih parametara modela\n",
    "save_params(theta, theta0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4665e9c-6f35-4a10-876f-774fad26bce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ucitavanje parametara\n",
    "theta, theta0 = load_params()\n",
    "\n",
    "# formiranje recnika za pd.DataFrame\n",
    "skl_theta_dict = {'$\\theta_0$': [theta0, ridge_reg.intercept_]}\n",
    "\n",
    "for i in range(len(ridge_reg.coef_)):\n",
    "    string = '$\\theta_{' + str(i+1) + '}$'\n",
    "    skl_theta_dict[string] = [theta[i], ridge_reg.coef_[i]]\n",
    "    \n",
    "skl_theta_df = pd.DataFrame(skl_theta_dict, index=['Implementacija', 'Scikit-learn']).transpose()\n",
    "skl_theta_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af22d597-abee-4e6a-a9f3-cfcf32d860b2",
   "metadata": {},
   "source": [
    "U prilog valjanosti modela ide i činjenica da su parametri, priloženi u tabeli iznad, vrlo sličnih vrednosti.\\\n",
    "\n",
    "Primetno je, da parametri $\\theta_1$ i $\\theta_4$ imaju znatno veće vrednosti od ostalih parametara, što bi značilo da učitan set podataka verovatno većinski potiče od raspodele prediktora $X_1$ i $X_4$ i potencijalno nekih korelisanih odbiraka prediktora $X_2$ i $X_4$, s obzirom na to da parametar $\\theta_{13}$ koji odgovara prediktoru $X_2X_4$ ima vrednost preko 11.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
